import json
from abc import ABC, abstractmethod
from typing import Any, Dict, Iterator, List, Tuple

from singer import (Transformer, get_bookmark, get_logger, metadata, metrics,
                    write_bookmark, write_record, write_schema)

from tap_delighted.utils import (DelightedPaginator,
                                 get_datetime_fields_from_schema,
                                 get_datetime_from_timestamp,
                                 get_timestamp_from_datetime,
                                 normalize_autopilot_record)

LOGGER = get_logger()


class BaseStream(ABC):
    """
    A Base Class providing structure and boilerplate for generic streams
    and required attributes for any kind of stream
    ~~~
    Provides:
     - Basic Attributes (stream_name,replication_method,key_properties)
     - Helper methods for catalog generation
     - `sync` and `get_records` method for performing sync
    """

    url_endpoint = ""
    path = ""
    page_size = 20
    next_page_key = ""
    headers = {'Accept': 'application/json', 'Content-Type': 'application/json'}
    children = []
    parent = ""
    data_key = ""
    parent_bookmark_key = ""
    http_method = "POST"

    def __init__(self, client=None, catalog=None) -> None:
        self.client = client
        self.catalog = catalog
        self.schema = catalog.schema.to_dict()
        self.metadata = metadata.to_map(catalog.metadata)
        self.child_to_sync = []
        self.params = {}
        self.data_payload = {}

    @property
    @abstractmethod
    def tap_stream_id(self) -> str:
        """Unique identifier for the stream.

        This is allowed to be different from the name of the stream, in
        order to allow for sources that have duplicate stream names.
        """

    @property
    @abstractmethod
    def replication_method(self) -> str:
        """Defines the sync mode of a stream."""

    @property
    @abstractmethod
    def replication_keys(self) -> List:
        """Defines the replication key for incremental sync mode of a
        stream."""

    @property
    @abstractmethod
    def key_properties(self) -> Tuple[str, str]:
        """List of key properties for stream."""

    def is_selected(self):
        return metadata.get(self.metadata, (), "selected")

    @abstractmethod
    def sync(
        self,
        state: Dict,
        transformer: Transformer,
        parent_obj: Dict = None,
    ) -> Dict:
        """
        Performs a replication sync for the stream.
        ~~~
        Args:
         - state (dict): represents the state file for the tap.
         - transformer (object): A Object of the singer.transformer class.
         - parent_obj (dict): The parent object for the stream.

        Returns:
         - bool: The return value. True for success, False otherwise.

        Docs:
         - https://github.com/singer-io/getting-started/blob/master/docs/SYNC_MODE.md
        """

    def get_records(self) -> Iterator:
        """Interacts with api client interaction and pagination."""
        self.params["per_page"] = self.page_size
        next_page = 1
        while next_page:
            response = self.client.make_request(
                self.http_method,
                self.url_endpoint,
                self.params,
                self.headers,
                body=json.dumps(self.data_payload),
                path=self.path
            )
            raw_records = response.get(self.data_key, [])
            next_page = response.get(self.next_page_key)

            self.params[self.next_page_key] = next_page
            yield from raw_records

    def write_schema(self) -> None:
        """
        Write a schema message.
        """
        try:
            write_schema(self.tap_stream_id, self.schema, self.key_properties)
        except OSError as err:
            LOGGER.error(
                "OS Error while writing schema for: {}".format(self.tap_stream_id)
            )
            raise err

    def update_params(self, **kwargs) -> None:
        """
        Update params for the stream
        """
        self.params.update(kwargs)

    def update_data_payload(self, **kwargs) -> None:
        """
        Update JSON body for the stream
        """
        self.data_payload.update(kwargs)

    def modify_object(self, record: Dict, parent_record: Dict = None) -> Dict:
        """
        Modify the record before writing to the stream
        """
        return record

    def get_url_endpoint(self, parent_obj: Dict = None) -> str:
        """
        Get the URL endpoint for the stream
        """
        return self.url_endpoint or f"{self.client.base_url}/{self.path}"


class IncrementalStream(BaseStream):
    """Base Class for Incremental Stream."""

    def get_bookmark(self, state: dict, stream: str, key: Any = None) -> int:
        """A wrapper for singer.get_bookmark to deal with compatibility for
        bookmark values or start values."""
        return get_bookmark(
            state,
            stream,
            key or self.replication_keys[0],
            self.client.config["start_date"],
        )

    def write_bookmark(self, state: dict, stream: str, key: Any = None, value: Any = None) -> Dict:
        """A wrapper for singer.get_bookmark to deal with compatibility for
        bookmark values or start values."""
        if not (key or self.replication_keys):
            return state

        current_bookmark = get_bookmark(state, stream, key or self.replication_keys[0], self.client.config["start_date"])
        value = max(current_bookmark, value)
        return write_bookmark(
            state, stream, key or self.replication_keys[0], value
        )

    def update_params(self, updated_since) -> None:
        api_filter_param = self.filter_param
        LOGGER.info(f"Updating params with filter param: {api_filter_param} and value: {updated_since}")
        self.params[api_filter_param] = updated_since
        self.params["per_page"] = self.page_size

    def get_records(self, paginator_obj: DelightedPaginator):
        """Interacts with api client interaction and pagination."""
        if self.is_page_number_pagination:
            yield from paginator_obj._page_number_pagination()
        else:
            yield from paginator_obj._cursor_pagination()

    def modify_object(self, record, parent_record=None, datetime_fields=set()):
        """ Modify the record's datetime fields before writing to the stream

        Args:
            record (Dict): The record to modify
            parent_record (Dict, optional): The parent record. Defaults to None.
            datetime_fields (Set[str], optional): The set of datetime fields. Defaults to set().
        """
        # Iterate on the record and convert datetime fields to standard format
        for field, value in record.items():
            if field in datetime_fields and value is not None:
                # Convert to standard datetime format
                try:
                    standardized_datetime = get_datetime_from_timestamp(value)
                    record[field] = standardized_datetime
                except Exception as e:
                    LOGGER.error("Error converting field {} with value {}: {}".format(field, value, str(e)))
                    record[field] = value  # Keep original value if conversion fails

            elif isinstance(value, dict):
                # Nested object, process recursively
                self.modify_object(value, datetime_fields=datetime_fields)

            elif isinstance(value, list):
                # List of items, process each item
                for item in value:
                    if isinstance(item, dict):
                        self.modify_object(item, datetime_fields=datetime_fields)

    def sync(
        self,
        state: Dict,
        transformer: Transformer,
        parent_obj: Dict = None,
    ) -> Dict:
        """Implementation for `type: Incremental` stream."""
        bookmark_date = self.get_bookmark(state, self.tap_stream_id)
        current_max_bookmark_date = bookmark_date
        current_max_bookmark_ts = get_timestamp_from_datetime(date_str=bookmark_date)
        self.update_params(updated_since=current_max_bookmark_ts)
        self.update_data_payload(parent_obj=parent_obj)
        self.url_endpoint = self.get_url_endpoint(parent_obj)

        # Get all the datetime fields from the schema
        datetime_fields = get_datetime_fields_from_schema(self.schema)

        # Initialise the paginator class since all
        # the streams are paginated
        paginator_obj = DelightedPaginator(
            client=self.client,
            params=self.params,
            headers=self.headers,
            http_method=self.http_method,
            path=self.path,
            url_endpoint=self.url_endpoint
        )

        with metrics.record_counter(self.tap_stream_id) as counter:
            for record in self.get_records(paginator_obj=paginator_obj):
                self.modify_object(record, parent_obj, datetime_fields=datetime_fields)

                if self.tap_stream_id.endswith("autopilot"):
                    # If the stream is email or sms autopilot, move the key_properties to root level
                    normalize_autopilot_record(record, self.key_properties)

                transformed_record = transformer.transform(
                    record, self.schema, self.metadata
                )
                record_bookmark = transformed_record[self.replication_keys[0]]
                record_bookmark_ts = get_timestamp_from_datetime(date_str=record_bookmark)

                if record_bookmark_ts >= current_max_bookmark_ts:
                    if self.is_selected():
                        write_record(self.tap_stream_id, transformed_record)
                        counter.increment()

                    current_max_bookmark_ts = max(
                        current_max_bookmark_ts, record_bookmark_ts
                    )

                    for child in self.child_to_sync:
                        child.sync(state=state, transformer=transformer, parent_obj=record)

            current_max_bookmark_date = get_datetime_from_timestamp(current_max_bookmark_ts)
            state = self.write_bookmark(state, self.tap_stream_id, value=current_max_bookmark_date)
            return counter.value


class FullTableStream(BaseStream):
    """Base Class for Incremental Stream."""

    replication_keys = []

    def get_records(self):
        response = self.client.make_request(
            self.http_method,
            self.url_endpoint,
            self.params,
            self.headers,
            body=json.dumps(self.data_payload),
            path=self.path
        )

        if isinstance(response, dict):
            raw_records = [response]

        yield from raw_records

    def sync(
        self,
        state: Dict,
        transformer: Transformer,
        parent_obj: Dict = None,
    ) -> Dict:
        """Abstract implementation for `type: Fulltable` stream."""
        self.url_endpoint = self.get_url_endpoint(parent_obj)
        self.update_data_payload(parent_obj=parent_obj)
        with metrics.record_counter(self.tap_stream_id) as counter:
            for record in self.get_records():
                transformed_record = transformer.transform(
                    record, self.schema, self.metadata
                )
                if self.is_selected():
                    write_record(self.tap_stream_id, transformed_record)
                    counter.increment()

                for child in self.child_to_sync:
                    child.sync(state=state, transformer=transformer, parent_obj=record)

            return counter.value


class ParentBaseStream(IncrementalStream):
    """Base Class for Parent Stream."""

    def get_bookmark(self, state: Dict, stream: str, key: Any = None) -> int:
        """A wrapper for singer.get_bookmark to deal with compatibility for
        bookmark values or start values."""

        min_parent_bookmark = (
            super().get_bookmark(state, stream) if self.is_selected() else None
        )
        for child in self.child_to_sync:
            bookmark_key = f"{self.tap_stream_id}_{self.replication_keys[0]}"
            child_bookmark = super().get_bookmark(
                state, child.tap_stream_id, key=bookmark_key
            )
            min_parent_bookmark = (
                min(min_parent_bookmark, child_bookmark)
                if min_parent_bookmark
                else child_bookmark
            )

        return min_parent_bookmark

    def write_bookmark(
        self, state: Dict, stream: str, key: Any = None, value: Any = None
    ) -> Dict:
        """A wrapper for singer.get_bookmark to deal with compatibility for
        bookmark values or start values."""
        if self.is_selected():
            super().write_bookmark(state, stream, value=value)

        for child in self.child_to_sync:
            bookmark_key = f"{self.tap_stream_id}_{self.replication_keys[0]}"
            super().write_bookmark(
                state, child.tap_stream_id, key=bookmark_key, value=value
            )

        return state


class ChildBaseStream(IncrementalStream):
    """Base Class for Child Stream."""

    def get_url_endpoint(self, parent_obj=None):
        """Prepare URL endpoint for child streams."""
        return f"{self.client.base_url}/{self.path.format(parent_obj['id'])}"

    def get_bookmark(self, state: Dict, stream: str, key: Any = None) -> int:
        """Singleton bookmark value for child streams."""
        if not self.bookmark_value:
            self.bookmark_value = super().get_bookmark(state, stream)

        return self.bookmark_value
